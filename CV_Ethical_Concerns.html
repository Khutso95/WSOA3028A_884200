<!DOCTYPE html>
<html lang="en" dir="ltr">

<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="Shepherd Modisha" />
    <title>Ethical Issues</title>

    <link rel="stylesheet" href="blogStyles.css" />
</head>

<body>
    <div class="main-container">
        <div class="HomeButton">
            <nav>
                <h1>
                    <a href="index.html">Shepherd Modisha</a>
                </h1>
            </nav>
        </div>

        <div class="back-button"><button>&#8678</button></div>
        <div class="forward-button"><button>&#8680</button></div>
        <div><button class="to-top">&#8679</button></div>
</div>
        <div class="Navigation">
            <nav>
                <h1>
                    <ul>
                        <li><a href="index.html">Home</a></li>
                        <li><a href="Shepherd.html">Blog</a></li>
                        <li><a href="Projects.html">Projects</a></li>
                        <li><a href="Press.html">Press</a></li>
                        <li><a href="About.html">About</a></li>
                        <li><a href="Blog.html">Academic</a></li>
                    </ul>
                </h1>
            </nav>
        </div>
        <div class="Background">
            <!-- Dropdown Menu -->
            <div class="MobileNavigation">
                <nav>
                    <h1>
                        <ul>
                            <li><a href="index.html">Home</a></li>
                            <li><a href="Shepherd.html">Blog</a></li>
                            <li><a href="Projects.html">Projects</a></li>
                            <li><a href="Press.html">Press</a></li>
                            <li><a href="About.html">About</a></li>
                            <li><a href="Blog.html">Academic</a></li>
                        </ul>
                    </h1>
                </nav>
            </div>
            <div class="BurgerNav">
                <div class="one"></div>
                <div class="two"></div>
                <div class="three"></div>
            </div>
            <div class="CloseNav">
                <h1>X</h1>
            </div>
            <h3>Ethical Concerns Over Computer Vision Research</h3>
            <article>
                <img src="images/compute-vision.jpeg"  alt="cmputer code" />
                <p>Author: Khutso Nkadimeng</p>
                <p>20 May 2020</p>
                <p>YOLO (You Only Look Once) creator Joseph Redmon, stopped doing Computer Vision research citing ethical concerns. His
                concerns are shared by many, privacy and military applications. His actions came in a discussion about the Conference
                and Workshop on Neural Information Processing Systems’ decision to ask researchers to include possible societal
                consequences of their work. The resulting Twitter discussion is very relevant to the question of the developer’s
                responsibility emphasised in this course.</p>
                <br>
                <img src="images/YOLO+algorithms,.png" alt="A tweet about YOLO creator" />
                <br>

                <p>Just like Joe, I used to believe that science was objective and independent of politics, but unlike him, my wake-up call
                came early as I had to confront pseudo-sciences like Social Darwinism. However, knowing how science could be bent to
                support a political agenda did very little to make me think software could serve that purpose too and more importantly,
                that I, as a programmer, make political choices with every line of code I write. Something as simple as an image size on
                my website has access implications, those with a poor internet connection cannot see it. But I could never imagine a
                software displaying such historic bias displayed by facial recognition systems.</p>

                <img src="images/elainebabey.png" alt="Elaine Babey's tweet" />
                <br>

                <p><a href="https://khutso95.github.io/WSOA3028A_884200/buolamwini18a.pdf">This</a> study found a 34.7% error rate in classifying dark-skinned females and 0.8% error rate in classifying
                light-skinned males. The facial recognition systems in question follow the historical pattern of discrimination with
                white males at the top, followed by white females, black males and then black females at the bottom. This reflects a
                larger and perpetual societal problem that needs to be rectified urgently. When reading these papers and articles all I
                saw were opportunities because I have faith in science and technology, I know solutions will be found, however, <a href="https://www.mirror.co.uk/tech/womans-lips-mistaken-open-mouth-21580543"  target="_blank">this</a>
                one offended me. British passport website rejected an application from a black woman because the software mistook her
                lips for an open mouth. Some of the advice given to rectify this include "try different lighting" and "you can still
                submit your photo if you believe it should be accepted (for example there’s a medical reason why your mouth appears to
                be open)”. Nowhere do they acknowledge that it could be because their system does not work as well for darker skin
                tones. This brings us to the question of responsibility, who should be held accountable for this?</p>

                <p>ACLU tested Amazon’s facial recognition software, <a href="https://www.aclu.org/blog/privacy-technology/surveillance-technologies/amazons-face-recognition-falsely-matched-28"  target="_blank">Rekognition</a>, it incorrectly matched 28 members of the US Congress
                with people who previously committed crimes. 39% of the false matches were people of colour. I believe Amazon’s
                engineers were aware of this problem and the management too, yet they were marketing this tool to law enforcement.
                Regulation can slow innovation and entrepreneurship; it should be structured as an incentive as opposed to an obstacle.
                I think there should be clear legislation allowing people to sue corporations and government departments if they are
                misidentified by these types of systems and it was not disclosed that the software has a built-in bias. Tobacco products
                make it clear to consumers that tobacco causes cancer and facial recognition applications must also disclose their flaws
                to customers, especially in important areas like law enforcement, security checks and home affairs related applications.</p>

                <p>In this way, creators of these technologies will be reluctant to market a product if they must admit publicly that it
                has a racial bias. And they would have to build it robustly to avoid lawsuits. Privacy violations must be subject to the
                same rules. It must be clearly stated where data is coming from and who has access to it. This way we will not need a
                bureaucratic office to enforce these laws, it will be in both the supplier and the user’s best interest to hold each
                other accountable.</p>

            </article>
        </div>
    </div>

    <script type="text/javascript" charset="utf-8" defer src="Code.js"></script>
</body>

</html>