<!DOCTYPE html>
<html lang="en" dir="ltr">

<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="Shepherd Modisha" />
    <title>Ethical Issues</title>

    <link rel="stylesheet" href="blogStyles.css" />
</head>

<body>
    <div class="main-container">
        <div class="HomeButton">
            <nav>
                <h1>
                    <a href="index.html">Shepherd Modisha</a>
                </h1>
            </nav>
        </div>

        <div class="back-button"><button>&#8678</button></div>
        <div class="forward-button"><button>&#8680</button></div>
        <div><button class="to-top">&#8679</button></div>
        
        <div class="Navigation">
            <nav>
                <h1>
                    <ul>
                        <li><a href="index.html">Home</a></li>
                        <li><a href="Shepherd.html">Blog</a></li>
                        <li><a href="Projects.html">Projects</a></li>
                        <li><a href="Press.html">Press</a></li>
                        <li><a href="About.html">About</a></li>
                        <li><a href="Blog.html">Academic</a></li>
                    </ul>
                </h1>
            </nav>
        </div>
        <div class="Background">
            <!-- Dropdown Menu -->
            <div class="MobileNavigation">
                <nav>
                    <h1>
                        <ul>
                            <li><a href="index.html">Home</a></li>
                            <li><a href="Shepherd.html">Blog</a></li>
                            <li><a href="Projects.html">Projects</a></li>
                            <li><a href="Press.html">Press</a></li>
                            <li><a href="About.html">About</a></li>
                            <li><a href="Blog.html">Academic</a></li>
                        </ul>
                    </h1>
                </nav>
            </div>
            <div class="BurgerNav">
                <div class="one"></div>
                <div class="two"></div>
                <div class="three"></div>
            </div>
            <div class="CloseNav">
                <h1>X</h1>
            </div>
            <h3>Ethical Concerns Over Computer Vision Research (2)</h3>
            <article>
                <img src="images/tech-eye.jpeg" alt="cmputer code" />
                <p>Author: Khutso Nkadimeng</p>
                <p>26 Jun 2020</p>
                <p>During the Apartheid era, the government had a network of “good blacks” known in the townships as <i>mpimpis</i> or officially,
                as informants. Their sole purpose was to inform on anyone with ideas to challenge the regime, they would testify against
                the likes Steve Biko hiding behind cardboard boxes. Across the Atlantic, J. Edgar Hoover was years ahead of Jimmy
                Kruger, he had Malcolm X and Martin Luther King Jr. under constant electronic surveillance. There is a theme in these
                historical facts that continues to persist to this day.</p>

                <p>When thinking about this article, I stopped to imagine how things would have been if Hoover or Kruger had millions of
                surveillance cameras and an army of engineers writing artificial intelligence algorithms to analyse the footage. I saw
                spy drones flying above Soweto, Johannesburg checkpoints equipped with facial recognition technology, <i>dompas</i> replaced
                with smartphone applications and movement tracked by GPS and clandestine search engines and then it occurred to me that
                what I am thinking about is occupied West Bank. The clandestine search engine is called Better Tomorrow and nicknamed
                “Occupation Google” because it could track any Palestinian using an extensive surveillance network installed by the
                Israeli military according to an <a href="https://www.nbcnews.com/news/all/why-did-microsoft-fund-israeli-firm-surveils-west-bank-palestinians-n1072116" target="_blank">article</a> on NBC. Better Tomorrow is a flagship product created by AnyVision, the
                Israeli company Microsoft recently <a href="https://www.zdnet.com/article/microsoft-heres-why-were-withdrawing-our-stake-in-facial-recognition-startup-anyvision/"
                    target="_blank">parted ways</a> with citing ethical concerns and lack of control over problematic
                facial recognition capabilities the company builds.</p>

                <p>Microsoft did not just end their relationship with AnyVision, they also vowed to not sell their facial recognition
                technology to law enforcement. During a Washington Post online <a href="https://twitter.com/postlive/status/1271116509625020417" target="_blank">event</a> Microsoft president said: "We’ve decided we will
                not sell facial-recognition technology to police departments in the United States until we have a national law in place,
                grounded in human rights, that will govern this technology.” Amazon and IBM took a similar stance earlier. For years
                activists have protested the use of face recognition technology due to its inaccuracies and bias, United States
                government agency, the National Institute of Standards and Technology (NIST) <a href="https://www.scientificamerican.com/article/how-nist-tested-facial-recognition-algorithms-for-racial-bias/" target="_blank">conducted a study</a> featuring 189 face
                recognition algorithms submitted by 99 developers, they found that most of the algorithms were 10 to 100 times more
                likely to inaccurately identify people of colour more especially black women when compared to white males. Assuming that
                the racial inaccuracy can be solved, the problems with face recognition takes three scarier paths, Mass Surveillance,
                Political Repression and Social Control.</p>

                <h4>Mass Surveillance</h4>
                
                <p>Quoting from <a href="https://www.nbcnews.com/news/all/why-did-microsoft-fund-israeli-firm-surveils-west-bank-palestinians-n1072116"
                    target="_blank">NBC</a>, "In 2007, based on conversations with former Israeli officials, Hebrew University researcher Yael
                Berda estimated that the Israeli government had a list of about 200,000 potential terrorists in the West Bank that it
                wanted to monitor — about a fifth of the West Bank’s male population at the time — as well as a list of 65,000
                individuals deemed to pose a criminal risk. Both lists included people suspected of specific offenses, as well as people
                considered worthy of scrutiny for other reasons — for example, criticizing Israel on Facebook or living in a village
                where Hamas is popular.”</p>

                <p>Palestinians are not the only ones under high tech microscope, Kashgar City in China is in the league of West Bank, <a href="https://www.nytimes.com/2019/05/22/world/asia/china-surveillance-xinjiang.html" target="_blank">New
                York Times reporters wrote</a> “At the click of a mouse, a technician explained, the police can pull up live video from any
                surveillance camera or take a closer look at anyone passing through one of the thousands of checkpoints in the city” the
                system in question was developed by Chinese state-owned military manufacturer China Electronics Technology Corporation
                and the government use it to monitor millions of Uighurs and other Muslims in Xinjiang</p>
                
                <h4>Political Repression</h4>
                <p>The reasons for spying on Steve Biko, Malcolm X and Martin Luther King Jr. were to suppress their ideas. To limit their
                political influence for they challenged the status quo. According to the New York Times, the mass surveillance of
                Muslims in China is aimed at ensuring that they do not challenge the Communist Party's rule. It is not hard to imagine
                democratic governments using these systems to identify protestors and arresting or silencing them.</p>

                <h4>Social Control</h4>
                
                <p>China is developing and testing its <a href="https://www.wired.co.uk/article/china-social-credit-system-explained" target="_blank">“citizen score”</a>  system. The systems collect data from corporations, government
                agencies and private citizens on individuals and gives them a score based on purchasing history, political posts on
                social media, behaviour, trustworthiness, and other aspects of life such as the behaviour of <a href="https://www.theatlantic.com/international/archive/2018/02/china-surveillance/552203/" target="_blank">family and
                friends</a> . Lower scores could result in being blacklisted and banned from accessing some services and job
                positions. <a href="https://www.privateinternetaccess.com/blog/in-china-your-credit-score-is-now-affected-by-your-political-opinions-and-your-friends-political-opinions/" target="_blank">“What China is doing here is selectively breeding its population to select against the trait of critical,
                independent thinking.”</a> </p>

                <p>We live in critical times, I look at all these technologies same way I look at rocket science, you can use it to put
                useful satellites on orbit, colonise Mars or you can send a warhead on the side of the world.</p>

            </article>
        </div>
    </div>

    <script type="text/javascript" charset="utf-8" defer src="Code.js"></script>
</body>

</html>